<div align="center">

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="separador" width="100%">

# ğŸ“Š Probabilidad y EstadÃ­stica Aplicadas al Machine Learning
### Fundamentos estadÃ­sticos para el anÃ¡lisis de datos y ML

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/colored.png" alt="separador" width="100%">

<p align="center">
  <img src="https://img.shields.io/badge/Dificultad-Intermedia-yellow?style=for-the-badge&logo=python" alt="Dificultad"/>
  <img src="https://img.shields.io/badge/Ãrea-EstadÃ­stica-green?style=for-the-badge&logo=numpy" alt="Ãrea"/>
  <img src="https://img.shields.io/badge/Python-Requerido-gr?style=for-the-badge&logo=python" alt="Python"/>
</p>

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/dark.png" alt="separador" width="100%">

</div>

## ğŸ“‘ Tabla de Contenidos

<details open>
<summary>Explora los conceptos ğŸ“ˆ</summary>

1. [ğŸ² Distribuciones NumÃ©ricas](#-distribuciones-numÃ©ricas)
2. [ğŸ“ Medidas de Tendencia Central](#-medidas-de-tendencia-central)
3. [ğŸ“Š Tipos de Variables](#-tipos-de-variables)
4. [ğŸ“ˆ Varianza y DesviaciÃ³n](#-varianza-y-desviaciÃ³n)
5. [ğŸ¯ MÃ©tricas de EvaluaciÃ³n](#-mÃ©tricas-de-evaluaciÃ³n)
6. [ğŸ¤– Modelos y TÃ©cnicas](#-modelos-y-tÃ©cnicas)

</details>

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/fire.png" alt="separador" width="100%">

## ğŸ² Distribuciones NumÃ©ricas

### ğŸ“Š DistribuciÃ³n Normal (Gaussiana)

> ğŸ’¡ **La distribuciÃ³n mÃ¡s importante en estadÃ­stica**

| Propiedad | DescripciÃ³n |
|:---------:|:------------|
| ğŸ”„ SimetrÃ­a | SimÃ©trica alrededor de la media |
| ğŸ”” Forma | CaracterÃ­stica forma de campana |
| ğŸ“ ParÃ¡metros | Î¼ (media) y Ïƒ (desviaciÃ³n estÃ¡ndar) |

```python
# VisualizaciÃ³n en Python
import numpy as np
import matplotlib.pyplot as plt

x = np.random.normal(loc=0, scale=1, size=1000)
plt.hist(x, bins=30, density=True)
```
### ğŸ“Š DistribuciÃ³n Binomial

> ğŸ’¡ **Uso en clasificaciÃ³n y teorema de Bayes**

| Propiedad | DescripciÃ³n |
|:---------:|:------------|
| ğŸ”„ Experimentos | NÃºmero fijo de ensayos |
| ğŸ”” Ã‰xitos | Probabilidad de Ã©xito en cada ensayo |

```python
# VisualizaciÃ³n de la distribuciÃ³n binomial
from scipy.stats import binom
import matplotlib.pyplot as plt

n = 10  # nÃºmero de ensayos
p = 0.5  # probabilidad de Ã©xito
x = range(n + 1)
pmf = binom.pmf(x, n, p)

plt.bar(x, pmf)
plt.title('DistribuciÃ³n Binomial')
plt.xlabel('NÃºmero de Ã‰xitos')
plt.ylabel('Probabilidad')
plt.show()
```

### ğŸ“Š DistribuciÃ³n Poisson

> ğŸ’¡ **Modelado de conteos de eventos**

| Propiedad | DescripciÃ³n |
|:---------:|:------------|
| ğŸ”„ Eventos | NÃºmero de eventos en un intervalo fijo |
| ğŸ”” ParÃ¡metro | Î» (tasa de eventos) |

```python
# VisualizaciÃ³n de la distribuciÃ³n de Poisson
from scipy.stats import poisson

lambda_ = 3  # tasa de eventos
x = range(0, 10)
pmf = poisson.pmf(x, lambda_)

plt.bar(x, pmf)
plt.title('DistribuciÃ³n de Poisson')
plt.xlabel('NÃºmero de Eventos')
plt.ylabel('Probabilidad')
plt.show()
```

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/solar.png" alt="separador" width="100%">

#  AnÃ¡lisis

El anÃ¡lisis de datos implica la interpretaciÃ³n de las distribuciones y medidas estadÃ­sticas para extraer conclusiones significativas. Se pueden utilizar tÃ©cnicas como la visualizaciÃ³n de datos y el anÃ¡lisis descriptivo.

## ğŸ“ Medidas de Tendencia Central

### ğŸ“Š Conceptos Fundamentales

<details open>
<summary><b>ğŸ“ˆ Medidas Principales</b></summary>

| Medida | DescripciÃ³n | FÃ³rmula |
|:------:|:------------|:--------:|
| ğŸ“Š Media | Promedio aritmÃ©tico | $xÌ„ = \frac{Î£x}{n}$ |
| ğŸ“ Mediana | Valor central | - |
| ğŸ“ˆ Moda | Valor mÃ¡s frecuente | - |
| ğŸ“‰ Rango | Diferencia max-min | $max(x) - min(x)$ |
| ğŸ“Š Varianza | Medida de dispersiÃ³n | $Ïƒ^2 = \frac{Î£(x - xÌ„)^2}{n}$ |
| ğŸ“ DesviaciÃ³n EstÃ¡ndar | RaÃ­z cuadrada de la varianza | $Ïƒ = \sqrt{Ïƒ^2}$ |
| ğŸ“ˆ Cuartiles | Dividen los datos en cuatro partes | - |
| ğŸ“‰ Percentiles | Dividen los datos en cien partes | - |

</details>

### ğŸ”„ VisualizaciÃ³n de Medidas

```mermaid
graph LR
    A[Datos] --> B[Media]
    A --> C[Mediana]
    A --> D[Moda]
    A --> E[Varianza]
    A --> F[DesviaciÃ³n EstÃ¡ndar]
    B --> G[SimetrÃ­a]
    C --> G
    D --> G
    E --> H[DispersiÃ³n]
    F --> H
```

### ğŸ“Š Ejemplo PrÃ¡ctico

```python
import pandas as pd

# Cargar datos
data = pd.DataFrame({'valores': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7]})

# Calcular medidas
media = data['valores'].mean()
mediana = data['valores'].median()
moda = data['valores'].mode()[0]
varianza = data['valores'].var()
desviacion_estandar = data['valores'].std()

print(f'Media: {media}, Mediana: {mediana}, Moda: {moda}, Varianza: {varianza}, DesviaciÃ³n EstÃ¡ndar: {desviacion_estandar}')
```

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="separador" width="100%">

### ğŸ“‰ Sesgo

El sesgo mide la asimetrÃ­a de la distribuciÃ³n de los datos. Puede ser positivo, negativo o nulo.

- **Sesgo Positivo**: La cola de la distribuciÃ³n se extiende mÃ¡s hacia la derecha.
- **Sesgo Negativo**: La cola de la distribuciÃ³n se extiende mÃ¡s hacia la izquierda.
- **Sesgo Nulo**: La distribuciÃ³n es simÃ©trica.

```python
from scipy.stats import skew

#Calcular el sesgo
sesgo = skew(data['valores'])
print(f'Sesgo: {sesgo}')
```

## ğŸ“Š Tipos de Variables

### ğŸ¯ ClasificaciÃ³n Principal

| Tipo | DescripciÃ³n | Ejemplo | VisualizaciÃ³n |
|:----:|:------------|:--------|:-------------:|
| ğŸ“‹ Nominal | CategorÃ­as sin orden | Colores | GrÃ¡fico de Barras |
| ğŸ“Š Ordinal | CategorÃ­as ordenadas | Calificaciones | GrÃ¡fico de Barras Ordenado |
| ğŸ”¢ Discreta | Valores contables | NÃºmero de hijos | Histograma |
| ğŸ“ˆ Continua | Valores en continuo | Altura | Densidad |
| ğŸ“ Uniforme | Todos los resultados tienen la misma probabilidad | NÃºmeros aleatorios | GrÃ¡fico de Barras |
| ğŸ“‰ Exponencial | Modela el tiempo entre eventos | Tiempo entre llegadas | GrÃ¡fico de Densidad |
| ğŸ“Š Log-Normal | Variables que crecen exponencialmente | Ingresos | Histograma |
| ğŸ“ˆ Gamma | Modela el tiempo hasta un evento | Tiempo de espera | GrÃ¡fico de Densidad |
| ğŸ“Š Beta | Variables acotadas en [0, 1] | Probabilidades | GrÃ¡fico de Densidad |

<div align="center">

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/solar.png" alt="separador" width="100%">

## ğŸ“Š AnÃ¡lisis EstadÃ­stico y Sesgo

## ğŸ“Š AnÃ¡lisis de Datos

El anÃ¡lisis de datos es un proceso fundamental en la estadÃ­stica y el machine learning que implica la inspecciÃ³n, limpieza y modelado de datos con el objetivo de descubrir informaciÃ³n Ãºtil, llegar a conclusiones y apoyar la toma de decisiones.

### ğŸ“ˆ TÃ©cnicas de VisualizaciÃ³n

Las tÃ©cnicas de visualizaciÃ³n son herramientas esenciales para representar datos de manera grÃ¡fica, facilitando la comprensiÃ³n de patrones, tendencias y anomalÃ­as. Algunas de las tÃ©cnicas mÃ¡s comunes incluyen:

- **ğŸ“Š GrÃ¡ficos de Barras**: Ãštiles para comparar cantidades entre diferentes categorÃ­as.
- **ğŸ“ˆ Histogramas**: Muestran la distribuciÃ³n de un conjunto de datos dividiÃ©ndolos en intervalos.
- **ğŸ” Diagramas de DispersiÃ³n**: Ayudan a visualizar la relaciÃ³n entre dos variables.
- **ğŸ“‰ GrÃ¡ficos de LÃ­neas**: Ideales para mostrar tendencias a lo largo del tiempo.

### ğŸ“‰ InterpretaciÃ³n de Resultados

La interpretaciÃ³n de los resultados es crucial para extraer conclusiones significativas. Al analizar grÃ¡ficos y estadÃ­sticas, es importante considerar:

- **ğŸ”¼ Tendencias**: Â¿Los datos muestran un aumento o disminuciÃ³n a lo largo del tiempo?
- **ğŸ”— Correlaciones**: Â¿Existen relaciones entre diferentes variables?
- **âš ï¸ AnomalÃ­as**: Â¿Hay datos que se desvÃ­an significativamente de la norma?

Un anÃ¡lisis cuidadoso y una visualizaciÃ³n efectiva pueden proporcionar informaciÃ³n valiosa que guÃ­e decisiones informadas en proyectos de machine learning y anÃ¡lisis de datos.


## ğŸ“Š TÃ©cnicas de Clustering

El clustering es una tÃ©cnica de anÃ¡lisis de datos que agrupa un conjunto de objetos de tal manera que los objetos en el mismo grupo (o clÃºster) son mÃ¡s similares entre sÃ­ que a los de otros grupos. Es ampliamente utilizado en diversas aplicaciones, como segmentaciÃ³n de mercado, anÃ¡lisis de imÃ¡genes y compresiÃ³n de datos.

# ğŸ“Š Tipos Comunes de Algoritmos de Clustering

1. **K-Means**: Un algoritmo que divide los datos en K clÃºsteres, donde cada clÃºster se representa por la media de sus puntos.
2. **Hierarchical Clustering**: Crea un Ã¡rbol de clÃºsteres que muestra la relaciÃ³n entre los diferentes grupos.
3. **DBSCAN**: Un algoritmo basado en densidad que agrupa puntos cercanos y marca los puntos aislados como ruido.
4. **Mean Shift**: Un algoritmo que busca los puntos de mayor densidad en el espacio de caracterÃ­sticas y agrupa los puntos alrededor de estos.

### ğŸ“ˆ Ejemplo de K-Means en Python


### ğŸ“‰ Sesgo
El sesgo en estadÃ­stica se refiere a la tendencia sistemÃ¡tica de un estimador a diferir del valor real del parÃ¡metro que se estÃ¡ estimando. En otras palabras, es la diferencia entre el valor esperado de un estimador y el valor verdadero del parÃ¡metro. Un sesgo puede ser positivo, negativo o nulo.

### ğŸ“‰ Impacto en Modelos de Machine Learning

| Tipo de Sesgo | DescripciÃ³n | Efecto en el Modelo |
|:-------------:|:------------|:--------------------|
| â¡ï¸ Positivo   | El modelo tiende a sobrestimar los resultados. | Predicciones consistentemente mÃ¡s altas. |
| â¬…ï¸ Negativo   | El modelo tiende a subestimar los resultados. | Predicciones consistentemente mÃ¡s bajas. |
| âš–ï¸ Nulo       | El modelo no tiene una tendencia sistemÃ¡tica. | Predicciones, en promedio, correctas. |

Es crucial identificar y corregir el sesgo en los modelos de machine learning, ya que un sesgo no controlado puede llevar a decisiones errÃ³neas basadas en predicciones inexactas.

### ğŸ“ˆ Conceptos de Sesgo

| Tipo de Sesgo | DescripciÃ³n | Impacto en ML |
|:-------------:|:------------|:--------------|
| â¡ï¸ Positivo | Cola hacia la derecha | Puede afectar predicciones |
| â¬…ï¸ Negativo | Cola hacia la izquierda | Requiere transformaciÃ³n |
| âš–ï¸ Nulo | DistribuciÃ³n simÃ©trica | Ideal para muchos modelos |

```python
from scipy.stats import skew
import numpy as np

# Calcular sesgo
datos = np.random.normal(0, 1, 1000)
sesgo = skew(datos)
print(f'Sesgo: {sesgo}')
```

## ğŸ¯ MÃ©tricas de EvaluaciÃ³n

### ğŸ“Š MÃ©tricas de EvaluaciÃ³n

Las mÃ©tricas de evaluaciÃ³n son fundamentales para medir el rendimiento de los modelos de machine learning. A continuaciÃ³n, se describen algunas de las mÃ©tricas mÃ¡s comunes:

| MÃ©trica | DescripciÃ³n |
|:-------:|:------------|
| âœ… **PrecisiÃ³n (Accuracy)** | ProporciÃ³n de predicciones correctas sobre el total de predicciones. Se utiliza para evaluar modelos de clasificaciÃ³n. |
| ğŸ“Š **PrecisiÃ³n (Precision)** | ProporciÃ³n de verdaderos positivos sobre el total de positivos predichos. Indica cuÃ¡ntas de las predicciones positivas son realmente correctas. |
| ğŸ“ˆ **Recall (Sensibilidad)** | ProporciÃ³n de verdaderos positivos sobre el total de positivos reales. Mide la capacidad del modelo para identificar correctamente las instancias positivas. |
| ğŸ“‰ **F1-Score** | La media armÃ³nica entre precisiÃ³n y recall. Es Ãºtil cuando se busca un balance entre ambas mÃ©tricas, especialmente en conjuntos de datos desbalanceados. |
| ğŸ“Š **MSE (Error CuadrÃ¡tico Medio)** | Promedio de los cuadrados de los errores, que mide la media de las diferencias al cuadrado entre los valores predichos y los reales. Se utiliza en problemas de regresiÃ³n. |

### Ejemplo de CÃ¡lculo de MÃ©tricas


### ğŸ“Š MÃ©tricas Principales

| MÃ©trica | Uso | FÃ³rmula |
|:-------:|:----|:--------|
| âœ… Accuracy | ClasificaciÃ³n | $\frac{TP + TN}{Total}$ |
| ğŸ“Š Precision | ClasificaciÃ³n | $\frac{TP}{TP + FP}$ |
| ğŸ“ˆ Recall | ClasificaciÃ³n | $\frac{TP}{TP + FN}$ |
| ğŸ“‰ F1-Score | ClasificaciÃ³n | $2 \times \frac{Precision \times Recall}{Precision + Recall}$ |
| ğŸ“Š MSE | RegresiÃ³n | $\frac{1}{n}\sum(y - \hat{y})^2$ |

## ğŸ¤– Modelos y TÃ©cnicas

### ğŸ“ˆ Modelos de RegresiÃ³n

La regresiÃ³n es una tÃ©cnica fundamental en el anÃ¡lisis de datos que permite modelar la relaciÃ³n entre una variable dependiente y una o mÃ¡s variables independientes. A continuaciÃ³n, se describen algunos de los modelos de regresiÃ³n mÃ¡s comunes y sus aplicaciones:

- ğŸ“Š **RegresiÃ³n Lineal**: Este modelo asume una relaciÃ³n lineal entre la variable dependiente y las variables independientes. Se utiliza ampliamente en situaciones donde se busca predecir un valor continuo, como el precio de una casa basado en sus caracterÃ­sticas.

- ğŸ“ˆ **RegresiÃ³n Polinomial**: A diferencia de la regresiÃ³n lineal, este modelo permite capturar relaciones no lineales al incluir tÃ©rminos polinÃ³micos. Es Ãºtil en casos donde la relaciÃ³n entre las variables no es lineal, como en el ajuste de curvas en datos experimentales.

- ğŸŒ² **Random Forest Regressor**: Este modelo utiliza un conjunto de Ã¡rboles de decisiÃ³n para realizar predicciones. Es robusto frente al sobreajuste y se utiliza en problemas complejos donde se requiere una alta precisiÃ³n, como en la predicciÃ³n de precios en mercados financieros.

- ğŸ”„ **SVR (Support Vector Regression)**: Este modelo se basa en el principio de los vectores de soporte y es eficaz en situaciones donde se desea una alta precisiÃ³n en la predicciÃ³n, incluso en presencia de ruido en los datos. Se utiliza en aplicaciones como la predicciÃ³n de series temporales.

### ğŸ“Š Modelos de ClasificaciÃ³n

- ğŸ¯ RegresiÃ³n LogÃ­stica
- ğŸŒ³ Ãrboles de DecisiÃ³n
- ğŸ¤ SVM (Support Vector Machines)
- ğŸ§  Redes Neuronales

### ğŸ” Clustering

- ğŸ“Š K-Means
- ğŸ“ˆ DBSCAN
- ğŸ¯ Clustering JerÃ¡rquico
- ğŸ“‰ Gaussian Mixture Models

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="separador" width="100%">

### ğŸ“ ReducciÃ³n de Dimensionalidad

La reducciÃ³n de dimensionalidad es una tÃ©cnica utilizada en el anÃ¡lisis de datos que busca simplificar un conjunto de datos al reducir el nÃºmero de variables (dimensiones) que se consideran, manteniendo al mismo tiempo la mayor cantidad de informaciÃ³n posible. Esto es especialmente Ãºtil en situaciones donde los datos son de alta dimensiÃ³n, lo que puede dificultar la visualizaciÃ³n y el anÃ¡lisis.

Algunas de las tÃ©cnicas mÃ¡s comunes para la reducciÃ³n de dimensionalidad incluyen:

- ğŸ“Š **PCA (AnÃ¡lisis de Componentes Principales)**: Esta tÃ©cnica transforma los datos a un nuevo sistema de coordenadas, donde las nuevas dimensiones (componentes principales) son combinaciones lineales de las dimensiones originales y estÃ¡n ordenadas de tal manera que la primera componente retiene la mayor varianza posible.

- ğŸ“ˆ **t-SNE (t-Distributed Stochastic Neighbor Embedding)**: Es un mÃ©todo no lineal que se utiliza principalmente para la visualizaciÃ³n de datos de alta dimensiÃ³n. t-SNE busca mantener la estructura local de los datos, agrupando puntos similares en el espacio reducido.

- ğŸ¯ **UMAP (Uniform Manifold Approximation and Projection)**: Similar a t-SNE, UMAP es una tÃ©cnica de reducciÃ³n de dimensionalidad que se basa en la teorÃ­a de la topologÃ­a y la geometrÃ­a. Es eficaz para preservar tanto la estructura local como la global de los datos.

- ğŸ“‰ **LDA (AnÃ¡lisis Discriminante Lineal)**: A diferencia de PCA, que es una tÃ©cnica no supervisada, LDA es supervisada y se utiliza para encontrar una combinaciÃ³n lineal de caracterÃ­sticas que mejor separa dos o mÃ¡s clases de objetos o eventos.

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" alt="separador" width="100%">

### ğŸš€ Â¡Domina la estadÃ­stica para Machine Learning!

[![GitHub](https://img.shields.io/badge/SÃ­gueme-en_GitHub-black?style=for-the-badge&logo=github)](https://github.com/Ansonii11)

<sub>Creado con â¤ï¸ para la comunidad de RevoluciÃ³n Digital</sub>

</div>

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/solar.png" alt="separador" width="100%">